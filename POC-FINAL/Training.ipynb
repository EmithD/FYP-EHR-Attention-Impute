{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where the model is trained.\n",
    "\n",
    "For the POC level the following will not be addressed:\n",
    "1. Hyperparameter tuning\n",
    "2. kNN pre-imputer\n",
    "3. Modifications and advancements to the model\n",
    "4. Use of temporal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'data/dat.csv'  # Replace with actual path if different\n",
    "ehr_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data Sample:\n",
      "   inpatient.number  visit.times  body.temperature  pulse  respiration  \\\n",
      "0            857781            1              36.7     87           19   \n",
      "1            743087            1              36.8     95           18   \n",
      "2            866418            2              36.5     98           18   \n",
      "3            775928            1              36.0     73           19   \n",
      "4            810128            1              35.0     88           19   \n",
      "\n",
      "   systolic.blood.pressure  diastolic.blood.pressure        map  weight  \\\n",
      "0                      102                        64  76.666667    50.0   \n",
      "1                      150                        70  96.666667    51.0   \n",
      "2                      102                        67  78.666667    70.0   \n",
      "3                      110                        74  86.000000    65.0   \n",
      "4                      134                        62  86.000000    76.0   \n",
      "\n",
      "   height  ...  carboxyhemoglobin  body.temperature.blood.gas  \\\n",
      "0    1.64  ...           0.400000                        37.0   \n",
      "1    1.63  ...           0.605645                        37.0   \n",
      "2    1.70  ...           0.605645                        37.0   \n",
      "3    1.70  ...           0.605645                        37.0   \n",
      "4    1.55  ...           0.605645                        37.0   \n",
      "\n",
      "   oxygen.saturation  partial.oxygen.pressure  oxyhemoglobin  anion.gap  \\\n",
      "0          97.000000                93.000000       95.90000  17.800000   \n",
      "1          95.806647               108.121853       94.93871  14.022457   \n",
      "2          95.806647               108.121853       94.93871  14.022457   \n",
      "3          95.806647               108.121853       94.93871  14.022457   \n",
      "4          95.806647               108.121853       94.93871  14.022457   \n",
      "\n",
      "   free.calcium  total.hemoglobin  GCS  dischargeDay  \n",
      "0      1.140000         125.00000   15            11  \n",
      "1      1.110393         124.08871   15             8  \n",
      "2      1.110393         124.08871   15             5  \n",
      "3      1.110393         124.08871   15            11  \n",
      "4      1.110393         124.08871   15             5  \n",
      "\n",
      "[5 rows x 150 columns]\n"
     ]
    }
   ],
   "source": [
    "# drop rows with >50% missing values\n",
    "cleaned_data = ehr_data.select_dtypes(include=['number']).dropna(thresh=ehr_data.shape[1] * 0.5)\n",
    "\n",
    "# Fill missing values with column means\n",
    "cleaned_data.fillna(cleaned_data.mean(), inplace=True)\n",
    "\n",
    "# Remove duplicates, completely empty and unnecessary columns\n",
    "cleaned_data = cleaned_data.drop_duplicates().dropna(axis=1, how='all')\n",
    "cleaned_data = cleaned_data.loc[:, cleaned_data.columns != 'Unnamed: 0']\n",
    "\n",
    "# Display the cleaned data head for verification\n",
    "print(\"Cleaned Data Sample:\")\n",
    "print(cleaned_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting data to a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EHR tensor shape: torch.Size([1987, 150])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ehr_tensor = torch.tensor(cleaned_data.values, dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"EHR tensor shape: {ehr_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
