{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation\n",
    "\n",
    "In this notebook the data will be manipulated to replicate the mechanisms mentioned in: <br>\n",
    "<i>Psychogyios, K. et al. (2023) ‘Missing Value Imputation Methods for Electronic Health Records’, IEEE Access, 11, pp. 21562–21574. Available at: https://doi.org/10.1109/ACCESS.2023.3251919.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (2008, 167)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dat.csv', encoding='utf-8')\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "\n",
    "target_column = 're.admission.within.6.months'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Keep only numerical features\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "df_numerical = df[numerical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Remove columns with >30% missing values\n",
    "missing_percentage = df_numerical.isnull().mean()\n",
    "columns_to_keep = missing_percentage[missing_percentage <= 0.3].index.tolist()\n",
    "df_filtered = df_numerical[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Calculate correlation matrix to select highly correlated features\n",
    "correlation_matrix = df_filtered.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Select top 39 features (based on correlation with other features)\n",
    "# Calculate average correlation for each feature\n",
    "avg_correlation = correlation_matrix.mean()\n",
    "top_features = avg_correlation.sort_values(ascending=False).head(39).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset 1 shape (39 features only): (2008, 39)\n",
      "Top 5 features selected: ['urea', 'direct.bilirubin', 'lactate.dehydrogenase', 'hemoglobin', 'prothrombin.activity']\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset 1: 39 feature columns only (for imputation evaluation)\n",
    "dataset_1 = df_filtered[top_features].copy()\n",
    "print(f\"\\nDataset 1 shape (39 features only): {dataset_1.shape}\")\n",
    "print(\"Top 5 features selected:\", top_features[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset 2 shape (39 features + target): (2008, 40)\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset 2: 39 features + target column (for prediction evaluation)\n",
    "# Check if target column exists in the dataframe\n",
    "if target_column in df.columns:\n",
    "    dataset_2 = dataset_1.copy()\n",
    "    dataset_2[target_column] = df[target_column]\n",
    "    print(f\"\\nDataset 2 shape (39 features + target): {dataset_2.shape}\")\n",
    "else:\n",
    "    print(f\"\\nTarget column '{target_column}' not found in the dataset.\")\n",
    "    dataset_2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset 1 saved as 'dataset_1_39_features.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save datasets to CSV\n",
    "dataset_1.to_csv('dataset_1_39_features.csv', index=False)\n",
    "print(\"\\nDataset 1 saved as 'dataset_1_39_features.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2 saved as 'dataset_2_39_features_plus_target.csv'\n"
     ]
    }
   ],
   "source": [
    "if dataset_2 is not None:\n",
    "    dataset_2.to_csv('dataset_2_39_features_plus_target.csv', index=False)\n",
    "    print(\"Dataset 2 saved as 'dataset_2_39_features_plus_target.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
