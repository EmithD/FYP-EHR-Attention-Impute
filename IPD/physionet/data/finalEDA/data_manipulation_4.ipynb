{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (2008, 167)\n",
      "Number of numerical columns: 152\n",
      "\n",
      "Columns with highest percentage of missing values:\n",
      "                                                                  column  \\\n",
      "cholinesterase                                            cholinesterase   \n",
      "time.of.death..days.from.admission.  time.of.death..days.from.admission.   \n",
      "homocysteine                                                homocysteine   \n",
      "lipoprotein                                                  lipoprotein   \n",
      "apolipoprotein.A                                        apolipoprotein.A   \n",
      "apolipoprotein.B                                        apolipoprotein.B   \n",
      "tricuspid.valve.return.pressure          tricuspid.valve.return.pressure   \n",
      "erythrocyte.sedimentation.rate            erythrocyte.sedimentation.rate   \n",
      "EA                                                                    EA   \n",
      "myoglobin                                                      myoglobin   \n",
      "\n",
      "                                     percent_missing  \n",
      "cholinesterase                            100.000000  \n",
      "time.of.death..days.from.admission.        97.808765  \n",
      "homocysteine                               92.729084  \n",
      "lipoprotein                                91.235060  \n",
      "apolipoprotein.A                           91.235060  \n",
      "apolipoprotein.B                           91.235060  \n",
      "tricuspid.valve.return.pressure            90.936255  \n",
      "erythrocyte.sedimentation.rate             84.711155  \n",
      "EA                                         80.428287  \n",
      "myoglobin                                  80.179283  \n",
      "\n",
      "Number of columns after removing those with >30% missing values: 108\n",
      "\n",
      "Number of highly correlated feature pairs: 35\n",
      "\n",
      "Examples of highly correlated features:\n",
      "lactate.dehydrogenase and glutamic.oxaloacetic.transaminase: 0.863\n",
      "hydroxybutyrate.dehydrogenase and lactate.dehydrogenase: 0.920\n",
      "cholesterol and low.density.lipoprotein.cholesterol: 0.898\n",
      "glutamyltranspeptidase and nucleotidase: 0.716\n",
      "white.globulin.ratio and globulin: 0.793\n",
      "\n",
      "Number of highly correlated features: 46\n",
      "\n",
      "Top 10 features by correlation involvement:\n",
      "verbal.response: involved in 3 high correlations\n",
      "eye.opening: involved in 3 high correlations\n",
      "movement: involved in 3 high correlations\n",
      "GCS: involved in 3 high correlations\n",
      "lactate.dehydrogenase: involved in 2 high correlations\n",
      "glutamic.oxaloacetic.transaminase: involved in 2 high correlations\n",
      "globulin: involved in 2 high correlations\n",
      "total.bilirubin: involved in 2 high correlations\n",
      "direct.bilirubin: involved in 2 high correlations\n",
      "indirect.bilirubin: involved in 2 high correlations\n",
      "\n",
      "Final number of selected features: 39\n",
      "\n",
      "Created datasets:\n",
      "1. physionet_39_features_only.csv: (2008, 39)\n",
      "2. physionet_39_features_and_target.csv: (2008, 40)\n",
      "\n",
      "Verified column counts:\n",
      "- Features only dataset: 39 columns\n",
      "- Features+target dataset: 40 columns\n",
      "\n",
      "Selected features:\n",
      "1. verbal.response\n",
      "2. eye.opening\n",
      "3. movement\n",
      "4. GCS\n",
      "5. lactate.dehydrogenase\n",
      "6. glutamic.oxaloacetic.transaminase\n",
      "7. globulin\n",
      "8. total.bilirubin\n",
      "9. direct.bilirubin\n",
      "10. indirect.bilirubin\n",
      "11. hemoglobin\n",
      "12. hematocrit\n",
      "13. red.blood.cell\n",
      "14. map\n",
      "15. return.to.emergency.department.within.6.months\n",
      "16. death.within.6.months\n",
      "17. death.within.28.days\n",
      "18. re.admission.within.3.months\n",
      "19. death.within.3.months\n",
      "20. hydroxybutyrate.dehydrogenase\n",
      "21. cholesterol\n",
      "22. low.density.lipoprotein.cholesterol\n",
      "23. glutamyltranspeptidase\n",
      "24. nucleotidase\n",
      "25. white.globulin.ratio\n",
      "26. glutamic.pyruvic.transaminase\n",
      "27. total.protein\n",
      "28. international.normalized.ratio\n",
      "29. prothrombin.time.ratio\n",
      "30. mean.corpuscular.volume\n",
      "31. mean.hemoglobin.volume\n",
      "32. neutrophil.count\n",
      "33. white.blood.cell\n",
      "34. platelet\n",
      "35. platelet.hematocrit\n",
      "36. eosinophil.ratio\n",
      "37. eosinophil.count\n",
      "38. basophil.ratio\n",
      "39. basophil.count\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the original dataset\n",
    "df = pd.read_csv('dat.csv')\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "\n",
    "# 1. Keep only numerical variables\n",
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "numerical_df = df[numerical_columns]\n",
    "print(f\"Number of numerical columns: {len(numerical_columns)}\")\n",
    "\n",
    "# 2. Calculate the percentage of missing values in each column\n",
    "missing_percentages = numerical_df.isnull().mean() * 100\n",
    "missing_info = pd.DataFrame({'column': numerical_df.columns,\n",
    "                             'percent_missing': missing_percentages})\n",
    "missing_info = missing_info.sort_values('percent_missing', ascending=False)\n",
    "\n",
    "print(\"\\nColumns with highest percentage of missing values:\")\n",
    "print(missing_info.head(10))\n",
    "\n",
    "# 3. Remove columns with more than 30% missingness\n",
    "columns_to_keep = missing_info[missing_info['percent_missing'] < 30]['column'].values\n",
    "filtered_df = numerical_df[columns_to_keep]\n",
    "print(f\"\\nNumber of columns after removing those with >30% missing values: {len(columns_to_keep)}\")\n",
    "\n",
    "# 4. Calculate correlation matrix to identify highly correlated features\n",
    "correlation_matrix = filtered_df.corr().abs()\n",
    "\n",
    "# 5. Find highly correlated pairs\n",
    "high_correlation_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if correlation_matrix.iloc[i, j] > 0.7:  # Using 0.7 as a threshold for high correlation\n",
    "            high_correlation_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j], \n",
    "                                          correlation_matrix.iloc[i, j]))\n",
    "\n",
    "print(f\"\\nNumber of highly correlated feature pairs: {len(high_correlation_pairs)}\")\n",
    "print(\"\\nExamples of highly correlated features:\")\n",
    "for pair in high_correlation_pairs[:5]:\n",
    "    print(f\"{pair[0]} and {pair[1]}: {pair[2]:.3f}\")\n",
    "\n",
    "# 6. Identify highly correlated features\n",
    "highly_correlated_features = set()\n",
    "for pair in high_correlation_pairs:\n",
    "    highly_correlated_features.add(pair[0])\n",
    "    highly_correlated_features.add(pair[1])\n",
    "    \n",
    "print(f\"\\nNumber of highly correlated features: {len(highly_correlated_features)}\")\n",
    "\n",
    "# 7. Sort features by their involvement in correlations\n",
    "feature_correlation_count = {}\n",
    "for pair in high_correlation_pairs:\n",
    "    feature_correlation_count[pair[0]] = feature_correlation_count.get(pair[0], 0) + 1\n",
    "    feature_correlation_count[pair[1]] = feature_correlation_count.get(pair[1], 0) + 1\n",
    "\n",
    "sorted_features = sorted(feature_correlation_count.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nTop 10 features by correlation involvement:\")\n",
    "for feature, count in sorted_features[:10]:\n",
    "    print(f\"{feature}: involved in {count} high correlations\")\n",
    "\n",
    "# 8. Select exactly 39 features based on correlation involvement\n",
    "target_column = 're.admission.within.6.months'\n",
    "features_to_select = []\n",
    "\n",
    "# Ensure target is not in the features list\n",
    "for feature, _ in sorted_features:\n",
    "    if feature != target_column and len(features_to_select) < 39:\n",
    "        features_to_select.append(feature)\n",
    "\n",
    "# If we don't have enough features, add more from columns with low missing percentage\n",
    "if len(features_to_select) < 39:\n",
    "    print(f\"\\nNeed {39 - len(features_to_select)} more features\")\n",
    "    remaining_columns = [col for col in columns_to_keep \n",
    "                         if col not in features_to_select and col != target_column]\n",
    "    \n",
    "    # Sort by missing percentage\n",
    "    remaining_cols_df = missing_info[missing_info['column'].isin(remaining_columns)]\n",
    "    remaining_cols_sorted = remaining_cols_df.sort_values('percent_missing')['column']\n",
    "    \n",
    "    features_to_select.extend(remaining_cols_sorted[:39-len(features_to_select)])\n",
    "\n",
    "# Ensure we have exactly 39 features\n",
    "features_to_select = features_to_select[:39]\n",
    "print(f\"\\nFinal number of selected features: {len(features_to_select)}\")\n",
    "\n",
    "# 9. Create the two datasets\n",
    "features_df = df[features_to_select]\n",
    "target_df = df[[target_column]]\n",
    "\n",
    "# Dataset 1: 39 features for imputation\n",
    "features_df.to_csv('physionet_39_features_only.csv', index=False)\n",
    "\n",
    "# Dataset 2: 39 features + target for prediction\n",
    "features_and_target_df = pd.concat([features_df, target_df], axis=1)\n",
    "features_and_target_df.to_csv('physionet_39_features_and_target.csv', index=False)\n",
    "\n",
    "print(\"\\nCreated datasets:\")\n",
    "print(f\"1. physionet_39_features_only.csv: {features_df.shape}\")\n",
    "print(f\"2. physionet_39_features_and_target.csv: {features_and_target_df.shape}\")\n",
    "\n",
    "# 10. Verify column counts and display feature names\n",
    "print(\"\\nVerified column counts:\")\n",
    "print(f\"- Features only dataset: {len(features_df.columns)} columns\")\n",
    "print(f\"- Features+target dataset: {len(features_and_target_df.columns)} columns\")\n",
    "\n",
    "print(\"\\nSelected features:\")\n",
    "for i, feature in enumerate(features_to_select, 1):\n",
    "    print(f\"{i}. {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
