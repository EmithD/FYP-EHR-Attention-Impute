{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2008, 39)\n"
     ]
    }
   ],
   "source": [
    "# Load the current dataset\n",
    "df = pd.read_csv('physionet_39_features.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target column 're.admission.within.6.months' exists in dataset: True\n"
     ]
    }
   ],
   "source": [
    "# Separate the target variable\n",
    "target_column = 're.admission.within.6.months'\n",
    "print(f\"Target column '{target_column}' exists in dataset: {target_column in df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current feature count: 38, need to add 1 more features\n",
      "Will proceed with available features\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataset with exactly 39 features (excluding the target variable)\n",
    "features_df = df.drop(columns=[target_column])\n",
    "\n",
    "# If we now have 38 features, we need to add one more\n",
    "if features_df.shape[1] < 39:\n",
    "    print(f\"Current feature count: {features_df.shape[1]}, need to add {39 - features_df.shape[1]} more features\")\n",
    "    \n",
    "    # We could consider adding another relevant feature from the original dataset here\n",
    "    # For now, we'll keep the existing features\n",
    "    \n",
    "    # Alternatively, if adding a feature is not possible, we could use all 38\n",
    "    print(\"Will proceed with available features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we somehow have more than 39 features, keep only the first 39\n",
    "if features_df.shape[1] > 39:\n",
    "    print(f\"Current feature count: {features_df.shape[1]}, need to remove {features_df.shape[1] - 39}\")\n",
    "    # Keep only the first 39 columns\n",
    "    features_df = features_df.iloc[:, :39]\n",
    "\n",
    "# Create a target df with just the target variable\n",
    "target_df = df[[target_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features-only dataset shape: (2008, 38)\n",
      "Features and target dataset shape: (2008, 39)\n",
      "Number of columns in features dataset: 38\n",
      "Number of columns in features+target dataset: 39\n",
      "\n",
      "Features dataset columns:\n",
      "['verbal.response', 'eye.opening', 'movement', 'GCS', 'lactate.dehydrogenase', 'glutamic.oxaloacetic.transaminase', 'globulin', 'total.bilirubin', 'direct.bilirubin', 'indirect.bilirubin', 'hemoglobin', 'hematocrit', 'red.blood.cell', 'map', 'return.to.emergency.department.within.6.months', 'death.within.6.months', 'death.within.28.days', 're.admission.within.3.months', 'death.within.3.months', 'hydroxybutyrate.dehydrogenase', 'cholesterol', 'low.density.lipoprotein.cholesterol', 'glutamyltranspeptidase', 'nucleotidase', 'white.globulin.ratio', 'glutamic.pyruvic.transaminase', 'total.protein', 'international.normalized.ratio', 'prothrombin.time.ratio', 'mean.corpuscular.volume', 'mean.hemoglobin.volume', 'neutrophil.count', 'white.blood.cell', 'platelet', 'platelet.hematocrit', 'eosinophil.ratio', 'eosinophil.count', 'basophil.ratio']\n",
      "\n",
      "Features+target dataset columns:\n",
      "['verbal.response', 'eye.opening', 'movement', 'GCS', 'lactate.dehydrogenase', 'glutamic.oxaloacetic.transaminase', 'globulin', 'total.bilirubin', 'direct.bilirubin', 'indirect.bilirubin', 'hemoglobin', 'hematocrit', 'red.blood.cell', 'map', 'return.to.emergency.department.within.6.months', 'death.within.6.months', 'death.within.28.days', 're.admission.within.3.months', 'death.within.3.months', 'hydroxybutyrate.dehydrogenase', 'cholesterol', 'low.density.lipoprotein.cholesterol', 'glutamyltranspeptidase', 'nucleotidase', 'white.globulin.ratio', 'glutamic.pyruvic.transaminase', 'total.protein', 'international.normalized.ratio', 'prothrombin.time.ratio', 'mean.corpuscular.volume', 'mean.hemoglobin.volume', 'neutrophil.count', 'white.blood.cell', 'platelet', 'platelet.hematocrit', 'eosinophil.ratio', 'eosinophil.count', 'basophil.ratio', 're.admission.within.6.months']\n"
     ]
    }
   ],
   "source": [
    "# Save dataset with just the features (for imputation evaluation)\n",
    "features_df.to_csv('physionet_features_only.csv', index=False)\n",
    "print(f\"Features-only dataset shape: {features_df.shape}\")\n",
    "\n",
    "# Save dataset with features and target (for post-imputation prediction)\n",
    "features_and_target_df = pd.concat([features_df, target_df], axis=1)\n",
    "features_and_target_df.to_csv('physionet_features_and_target.csv', index=False)\n",
    "print(f\"Features and target dataset shape: {features_and_target_df.shape}\")\n",
    "\n",
    "# Verify column counts\n",
    "print(f\"Number of columns in features dataset: {len(features_df.columns)}\")\n",
    "print(f\"Number of columns in features+target dataset: {len(features_and_target_df.columns)}\")\n",
    "\n",
    "# Print column names of both datasets\n",
    "print(\"\\nFeatures dataset columns:\")\n",
    "print(features_df.columns.tolist())\n",
    "\n",
    "print(\"\\nFeatures+target dataset columns:\")\n",
    "print(features_and_target_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2008, 39)\n",
      "Target column 're.admission.within.6.months' exists in dataset: True\n",
      "Current feature count: 38, need to add 1 more features\n",
      "Added 'red.to.white.cell.ratio' as the 39th feature\n",
      "Features-only dataset shape: (2008, 39)\n",
      "Features and target dataset shape: (2008, 40)\n",
      "Number of columns in features dataset: 39\n",
      "Number of columns in features+target dataset: 40\n",
      "\n",
      "First 5 columns of features dataset:\n",
      "['verbal.response', 'eye.opening', 'movement', 'GCS', 'lactate.dehydrogenase']\n",
      "\n",
      "Last 5 columns of features dataset:\n",
      "['platelet.hematocrit', 'eosinophil.ratio', 'eosinophil.count', 'basophil.ratio', 'red.to.white.cell.ratio']\n",
      "\n",
      "Last 5 columns of features+target dataset:\n",
      "['eosinophil.ratio', 'eosinophil.count', 'basophil.ratio', 'red.to.white.cell.ratio', 're.admission.within.6.months']\n",
      "\n",
      "Successfully created dataset with exactly 39 features!\n",
      "Successfully created features+target dataset with the target as the 40th column!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the current dataset\n",
    "df = pd.read_csv('physionet_39_features.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Separate the target variable\n",
    "target_column = 're.admission.within.6.months'\n",
    "print(f\"Target column '{target_column}' exists in dataset: {target_column in df.columns}\")\n",
    "\n",
    "# Create a new dataset with features (excluding the target variable)\n",
    "features_df = df.drop(columns=[target_column])\n",
    "\n",
    "# If we now have 38 features, we need to add one more to reach 39\n",
    "if features_df.shape[1] < 39:\n",
    "    print(f\"Current feature count: {features_df.shape[1]}, need to add {39 - features_df.shape[1]} more features\")\n",
    "    \n",
    "    # Add a new derived feature to reach 39 features\n",
    "    # Create a meaningful feature: red-to-white blood cell ratio\n",
    "    if 'red.blood.cell' in features_df.columns and 'white.blood.cell' in features_df.columns:\n",
    "        features_df['red.to.white.cell.ratio'] = features_df['red.blood.cell'] / features_df['white.blood.cell']\n",
    "        print(\"Added 'red.to.white.cell.ratio' as the 39th feature\")\n",
    "    # Alternative: calculate lab value ratios\n",
    "    elif 'hemoglobin' in features_df.columns and 'hematocrit' in features_df.columns:\n",
    "        features_df['hemoglobin.to.hematocrit.ratio'] = features_df['hemoglobin'] / features_df['hematocrit']\n",
    "        print(\"Added 'hemoglobin.to.hematocrit.ratio' as the 39th feature\")\n",
    "    # If neither option is available, create a compound feature from existing ones\n",
    "    else:\n",
    "        # Use columns that would likely have a meaningful relationship\n",
    "        numeric_cols = features_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        if len(numeric_cols) >= 2:\n",
    "            col1, col2 = numeric_cols[0], numeric_cols[1]\n",
    "            features_df[f'{col1}_to_{col2}_ratio'] = features_df[col1] / features_df[col2]\n",
    "            print(f\"Added '{col1}_to_{col2}_ratio' as the 39th feature\")\n",
    "\n",
    "# If we somehow have more than 39 features, keep only the first 39\n",
    "if features_df.shape[1] > 39:\n",
    "    print(f\"Current feature count: {features_df.shape[1]}, need to remove {features_df.shape[1] - 39}\")\n",
    "    # Keep only the first 39 columns\n",
    "    features_df = features_df.iloc[:, :39]\n",
    "\n",
    "# Create a target df with just the target variable\n",
    "target_df = df[[target_column]]\n",
    "\n",
    "# Save dataset with just the features (for imputation evaluation)\n",
    "features_df.to_csv('physionet_39_features_only.csv', index=False)\n",
    "print(f\"Features-only dataset shape: {features_df.shape}\")\n",
    "\n",
    "# Save dataset with features and target (for post-imputation prediction)\n",
    "features_and_target_df = pd.concat([features_df, target_df], axis=1)\n",
    "features_and_target_df.to_csv('physionet_39_features_and_target.csv', index=False)\n",
    "print(f\"Features and target dataset shape: {features_and_target_df.shape}\")\n",
    "\n",
    "# Verify column counts\n",
    "print(f\"Number of columns in features dataset: {len(features_df.columns)}\")\n",
    "print(f\"Number of columns in features+target dataset: {len(features_and_target_df.columns)}\")\n",
    "\n",
    "# Print first few columns of both datasets\n",
    "print(\"\\nFirst 5 columns of features dataset:\")\n",
    "print(features_df.columns[:5].tolist())\n",
    "\n",
    "print(\"\\nLast 5 columns of features dataset:\")\n",
    "print(features_df.columns[-5:].tolist())\n",
    "\n",
    "print(\"\\nLast 5 columns of features+target dataset:\")\n",
    "print(features_and_target_df.columns[-5:].tolist())\n",
    "\n",
    "# Check if we've achieved exactly 39 features\n",
    "if len(features_df.columns) == 39:\n",
    "    print(\"\\nSuccessfully created dataset with exactly 39 features!\")\n",
    "else:\n",
    "    print(f\"\\nWarning: Feature dataset has {len(features_df.columns)} features instead of 39\")\n",
    "\n",
    "# Check if the target is correctly added as the 40th column in the second dataset\n",
    "if len(features_and_target_df.columns) == 40 and features_and_target_df.columns[-1] == target_column:\n",
    "    print(\"Successfully created features+target dataset with the target as the 40th column!\")\n",
    "else:\n",
    "    print(\"Warning: Issue with the features+target dataset structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
