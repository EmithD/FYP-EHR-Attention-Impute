{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'dat.csv'  # Replace with actual path if different\n",
    "ehr_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data Sample:\n",
      "   Unnamed: 0  inpatient.number  visit.times  body.temperature  pulse  \\\n",
      "0           1            857781            1              36.7     87   \n",
      "1           2            743087            1              36.8     95   \n",
      "2           3            866418            2              36.5     98   \n",
      "3           4            775928            1              36.0     73   \n",
      "4           5            810128            1              35.0     88   \n",
      "\n",
      "   respiration  systolic.blood.pressure  diastolic.blood.pressure        map  \\\n",
      "0           19                      102                        64  76.666667   \n",
      "1           18                      150                        70  96.666667   \n",
      "2           18                      102                        67  78.666667   \n",
      "3           19                      110                        74  86.000000   \n",
      "4           19                      134                        62  86.000000   \n",
      "\n",
      "   weight  ...  carboxyhemoglobin  body.temperature.blood.gas  \\\n",
      "0    50.0  ...           0.400000                        37.0   \n",
      "1    51.0  ...           0.605645                        37.0   \n",
      "2    70.0  ...           0.605645                        37.0   \n",
      "3    65.0  ...           0.605645                        37.0   \n",
      "4    76.0  ...           0.605645                        37.0   \n",
      "\n",
      "   oxygen.saturation  partial.oxygen.pressure  oxyhemoglobin  anion.gap  \\\n",
      "0          97.000000                93.000000       95.90000  17.800000   \n",
      "1          95.806647               108.121853       94.93871  14.022457   \n",
      "2          95.806647               108.121853       94.93871  14.022457   \n",
      "3          95.806647               108.121853       94.93871  14.022457   \n",
      "4          95.806647               108.121853       94.93871  14.022457   \n",
      "\n",
      "   free.calcium  total.hemoglobin  GCS  dischargeDay  \n",
      "0      1.140000         125.00000   15            11  \n",
      "1      1.110393         124.08871   15             8  \n",
      "2      1.110393         124.08871   15             5  \n",
      "3      1.110393         124.08871   15            11  \n",
      "4      1.110393         124.08871   15             5  \n",
      "\n",
      "[5 rows x 152 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Cleaning\n",
    "# Drop non-numerical columns\n",
    "numeric_data = ehr_data.select_dtypes(include=['number'])\n",
    "\n",
    "# Drop rows with excessive missing values (e.g., more than 50% missing)\n",
    "cleaned_data = numeric_data.dropna(thresh=len(numeric_data.columns) * 0.5)\n",
    "\n",
    "# Fill remaining missing values with the mean of each column\n",
    "cleaned_data = cleaned_data.fillna(cleaned_data.mean())\n",
    "\n",
    "# Remove duplicate rows, if any\n",
    "cleaned_data = cleaned_data.drop_duplicates()\n",
    "\n",
    "# Display the cleaned data head for verification\n",
    "print(\"Cleaned Data Sample:\")\n",
    "print(cleaned_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing all-NaN columns: (1998, 151)\n"
     ]
    }
   ],
   "source": [
    "# Step to remove columns with only NaN values\n",
    "cleaned_data = cleaned_data.dropna(axis=1, how='all')\n",
    "\n",
    "# Re-check the cleaned data after removing all-NaN columns\n",
    "print(f\"Shape after removing all-NaN columns: {cleaned_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting data to a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EHR tensor shape: torch.Size([1998, 151])\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to a PyTorch tensor\n",
    "ehr_tensor = torch.tensor(cleaned_data.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Print tensor shape to confirm\n",
    "print(f\"EHR tensor shape: {ehr_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emith\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:472: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "c:\\Users\\emith\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:489: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the cleaned data\n",
    "normalized_data = scaler.fit_transform(cleaned_data)\n",
    "\n",
    "# Convert the normalized data to a PyTorch tensor and move it to the device\n",
    "ehr_tensor_normalized = torch.tensor(normalized_data, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
